{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, KFold , train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = joblib.load(\"datos/data_train.joblib\")\n",
    "df_test = joblib.load(\"datos/data_test.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder y selector de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 0.3.2 version. Select nrows to a small number when running on huge datasets.\n",
      "output = featurewiz(dataname, target, corr_limit=0.90, verbose=2, sep=',', \n",
      "\t\theader=0, test_data='',feature_engg='', category_encoders='',\n",
      "\t\tdask_xgboost_flag=False, nrows=None, skip_sulov=False, skip_xgboost=False)\n",
      "Create new features via 'feature_engg' flag : ['interactions','groupby','target']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fwiz = joblib.load(\"modelos/fwiz.joblib\")\n",
    "cat_econder = joblib.load(\"modelos/cat_econder.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar encoder y selector de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_t = cat_econder.transform(df_train.drop(columns=['clean_valor_total_avaluo']))\n",
    "X_test_t = cat_econder.transform(df_test.drop(columns=['clean_valor_total_avaluo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_selected = pd.concat([fwiz.transform(X_train_t), df_train['clean_valor_total_avaluo']], axis=1)\n",
    "X_test_selected = pd.concat([fwiz.transform(X_test_t), df_test['clean_valor_total_avaluo']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = df_train['clean_valor_total_avaluo']\n",
    "y_test = df_test['clean_valor_total_avaluo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterar modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir parámetros para cada modelo\n",
    "\n",
    "rf_space = { \n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 2, 10, 1)),\n",
    "    'n_estimators':scope.int(hp.quniform('n_estimators', 5, 500, 1))\n",
    "}\n",
    "\n",
    "xgb_space = { \n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 2, 10, 1)),\n",
    "    'n_estimators':scope.int(hp.quniform('n_estimators', 5, 500, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "}\n",
    "\n",
    "lgbm_space = { \n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 2, 10, 1)),\n",
    "    'n_estimators':scope.int(hp.quniform('n_estimators', 5, 500, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "}\n",
    "\n",
    "gb_space = { \n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 2, 10, 1)),\n",
    "    'n_estimators':scope.int(hp.quniform('n_estimators', 5, 500, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "}\n",
    "\n",
    "et_space = { \n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 2, 10, 1))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params, model, run_name):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model.set_params(**params)\n",
    "\n",
    "        # Define the k-fold cross-validation\n",
    "        cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "        # Use MAPE as the scoring metric for grid search\n",
    "        scoring = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "        cv_results = cross_validate(model, X_train_t, y_train, cv=cv, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "        # Calculate the average MAPE using cross-validation\n",
    "        mape_train = -cv_results['test_score'].mean()\n",
    "\n",
    "        # Refit model with all data\n",
    "        model.fit(X_train_t, y_train)\n",
    "        y_pred_test = model.predict(X_test_t)\n",
    "\n",
    "        # Calculta mape on test set\n",
    "        mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "\n",
    "        # Log the results in MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric('MAPE_train', mape_train)\n",
    "        mlflow.log_metric('MAPE_test', mape_test)\n",
    "   \n",
    "    return mape_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the run_experiment function\n",
    "def run_experiment(model, space, run_name, n_trials=20):\n",
    "    fmin_objective = partial(objective, model=model, run_name=run_name)        \n",
    "    trials = Trials()\n",
    "    best_result = fmin(fn = fmin_objective, space = space, algo = tpe.suggest, max_evals = n_trials, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_id = mlflow.set_experiment(experiment_name=\"optimizacion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [02:30<00:00,  3.01s/trial, best loss: 0.15754446568827543]\n",
      "100%|████████████████████████████████████████████████| 50/50 [16:26<00:00, 19.73s/trial, best loss: 0.1348133784172402]\n",
      "100%|███████████████████████████████████████████████| 50/50 [19:06<00:00, 22.94s/trial, best loss: 0.16666746128618037]\n",
      "100%|█████████████████████████████████████████████| 50/50 [1:41:52<00:00, 122.24s/trial, best loss: 0.1373119253304316]\n",
      "100%|████████████████████████████████████████████████| 50/50 [04:27<00:00,  5.36s/trial, best loss: 0.2095488864922687]\n"
     ]
    }
   ],
   "source": [
    "run_experiment(LGBMRegressor(n_jobs=-1, verbose=-1), lgbm_space, run_name='optimizacion_lgbm', n_trials=50)\n",
    "run_experiment(XGBRegressor(n_jobs=-1), xgb_space, run_name='optimizacion_xgb', n_trials=50)\n",
    "run_experiment(RandomForestRegressor(n_jobs=-1), rf_space, run_name='optimizacion_rf', n_trials=50)\n",
    "run_experiment(GradientBoostingRegressor(), gb_space, run_name='optimizacion_gb', n_trials=50)\n",
    "run_experiment(ExtraTreesRegressor(n_jobs=-1), et_space, run_name='optimizacion_et', n_trials=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "despliegue2",
   "language": "python",
   "name": "despliegue2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
