{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/15/xf5dyfhj20389_6yb1jydp8w0000gn/T/ipykernel_21113/2619455102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, KFold , train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.indexes.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniela/Documents/GitHub/miad_proyecto_despliegue/codigo/07- Iteracion modelos.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/daniela/Documents/GitHub/miad_proyecto_despliegue/codigo/07-%20Iteracion%20modelos.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_train \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mdatos/data_train.joblib\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(name) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(module) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[39mraise\u001b[39;00m UnpicklingError(\u001b[39m\"\u001b[39m\u001b[39mSTACK_GLOBAL requires str\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_class(module, name))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[39melif\u001b[39;00m module \u001b[39min\u001b[39;00m _compat_pickle\u001b[39m.\u001b[39mIMPORT_MAPPING:\n\u001b[1;32m   1579\u001b[0m         module \u001b[39m=\u001b[39m _compat_pickle\u001b[39m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[0;32m-> 1580\u001b[0m \u001b[39m__import__\u001b[39m(module, level\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _getattribute(sys\u001b[39m.\u001b[39mmodules[module], name)[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.indexes.numeric'"
     ]
    }
   ],
   "source": [
    "df_train = joblib.load(\"datos/data_train.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder y selector de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwiz = joblib.load(\"modelos/fwiz.joblib\")\n",
    "cat_econder = joblib.load(\"modelos/cat_econder.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar encoder y selector de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = cat_econder.transform(df_train.drop(columns=['clean_valor_total_avaluo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = pd.concat([fwiz.transform(X_train_t), df_train['clean_valor_total_avaluo']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X_train_selected.drop('clean_valor_total_avaluo', axis=1)\n",
    "y = X_train_selected['clean_valor_total_avaluo']\n",
    "\n",
    "# Dividir datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterar modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest regressor\n",
    "# xgboost regressor\n",
    "#lgbm regressor \n",
    "#gradient boosting regressor\n",
    "#decision tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la cuadrícula de parámetros para cada modelo\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20],\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, param_grid, model_name, run_name):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Definir la validación cruzada k-fold\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # Utilizar la métrica MAPE en la búsqueda en cuadrícula\n",
    "        scoring = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "        # Realizar la búsqueda en cuadrícula con validación cruzada\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring=scoring, cv=cv)\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Obtener los mejores parámetros y el modelo ajustado\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Calcular la métrica MAPE promedio utilizando validación cruzada\n",
    "        mape_scores = -grid_search.cv_results_['mean_test_score']\n",
    "        average_mape = mape_scores.mean()\n",
    "\n",
    "        # Registrar los resultados en MLflow\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric('Average_MAPE', average_mape)\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar experimentos para cada modelo\n",
    "run_experiment(RandomForestRegressor(), param_grid_rf, 'RandomForestRegressor', run_name='experiment_rf')\n",
    "run_experiment(XGBRegressor(), param_grid_xgb, 'XGBRegressor', run_name='experiment_xgb')\n",
    "run_experiment(LGBMRegressor(), param_grid_lgbm, 'LGBMRegressor', run_name='experiment_lgbm')\n",
    "run_experiment(GradientBoostingRegressor(), param_grid_gb, 'GradientBoostingRegressor', run_name='experiment_gb')\n",
    "run_experiment(DecisionTreeRegressor(), param_grid_dt, 'DecisionTreeRegressor', run_name='experiment_dt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
